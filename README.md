# Fine-tuning RoBertA model with Twitter Sentiment data

In this repository you can find a set of tools to automatically fine-tune a RoBertA base model ([Hugging Face](https://huggingface.co/roberta-base)) with Twitter sentiment data (more info on [Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140).

## High level overview
The overarching goal is to make the LLM to be able to correctly classify good or bad Twitter sentiment.
In order to achieve that, the training is comprised of two steps:
- Fine-tuning Masked Language Modelling task (more info see [Hugging Face](https://huggingface.co/course/chapter7/3?fw=tf))
- Fine-tuning on classification task

**Please note**: both tasks are trained on the same dataset

## Code Base
The code is comprised of three main sections:
- the main one: which contains all the necessary scripts to make it run on Ubuntu 22.04 EC2 machine (with GPU)
- notebooks: contains some exploration made with Jupyter notebook (TO BE DELETED)
- training_language_model: contains all the relevant code used to create the Docker images of the two fine-tuning steps

## How it works?
Considering using this on EC2 machine (GPU enabled) with Ubuntu 22.04.
First we need to bootstrap our environment:
- run prepare_docker.sh
- run prepare_docker_compose.sh
- run install_NVIDIA_docker_toolkit.sh
- run install_ubuntu_NVIDIA_drivers.sh

Then we can call Docker compose:
- generate a .env* file
- run 'docker compose up **service_name** 

The two services are generated by two docker images:
- [trainining_mlm](https://hub.docker.com/repository/docker/andret94/training_language_model-training_mlm/general): fine tune on masked language modelling
- [training_clf](https://hub.docker.com/repository/docker/andret94/training_language_model-training_clf/general): fine tune on classification

**Please note**: you can build new images by using the code inside training_language_model folder.

#### .env file generation
Generate an .env file with the below information:
**INPUT NECESSARY**
- HF_USER= your Hugging Face username, to push the model to Hugging Face Hub
- HF_TOKEN= your Hugging Face token, to push the model to Hugging Face Hub
**NEED TO CHANGE ONLY IF YOU WANT TO CHANGE THE CODE BASE (new model, different mount point, new dataset)**
- DIRPATH=data 
- MODEL_VERSION_MLM=roberta-fine-tuned-twitter
- MODEL_VERSION_CLF=roberta-fine-tuned-twitter-sentiment
- DATASET_VERSION=TwitterSentiment140


TODO LIST

OVERALL
- put todos in tickets

ON MODEL TRAINING
- create a tech debt/improvents section
- add a proposal to develop script that send artifacts back to my laptop
- add proposal of using S3 (both as mount to use datasets and for uploading trained models)
- specify how model training section with docker works in my bot architecture
- Train on cloud 1st model
- Push best 1st to HFHub and train 2nd model
- Script for saving model from EC2 machine back to mu laptop
- OPTIONAL FROM NOW ON
- Create central GitHub repo all models (both 1st and 2nd step) (as did be them https://github.com/cardiffnlp/timelms)
- small script for pushing selected best model to HFHub (and make training script save only models locally)
- Add on HF eval metrics, reference to GitHub, hyperparam and any tag to consider each card as a different model version (e.g. "no processing")
- test against TweetBert and this model https://huggingface.co/blog/sentiment-analysis-twitter
- If TweetBert is better, wrap it around torch to be served
- Fine-tune chosen model hps (like batch, max len) on new Twitter data
- Test lr+lr scheduler, different batch size (https://medium.com/distributed-computing-with-ray/
hyperparameter-optimization-for-transformers-a-guide-c4e32c6c989b)
- swith to W&B
- Logs idea: how many inputs are impacted by MAX_LEN in prod? Useful since hp tuned by training only
- Validation: against fear-greed index
- Analysis: Test if cleaning processing (copy from article) improve performance

ON MODE INFERENCE (SENTIMENT ANALYZER)
- Build API (how to load the model/tokenizer in Pytorch (.tar with state dict https://pytorch.org/tutorials/beginner/saving_loading_models.html))
NEXT STEPS
- Add Gantry and Grafana for prod logs
- Add logs for inference ML in prod (train-serving skew, data drift, uptime, latency, thorughtput) 
